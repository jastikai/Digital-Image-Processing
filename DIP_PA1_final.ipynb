{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division   # Python 2/3 compatibility\n",
    "from skimage import io, img_as_ubyte              # utilities to read and write images in various formats\n",
    "import numpy as np                                # array manipulation package\n",
    "import matplotlib.pylab as plt                    # plotting package\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 16)         # set default figure size\n",
    "plt.rcParams['image.cmap'] = 'gray'               # set default colormap to gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digital Image Processing - Programming Assignment \n",
    "\n",
    "The following progamming assignment involves two tasks, viz.: basic histogram processing and spatial domain image filtering tasks, i.e., image sharpening. The deadline for returning your work is **28 March 2022 at 23:59. Please, follow carefully the submission instructions given in the end of this notebook.** You are encouraged to seek information in other places than the course book and lecture material but remember **list all your sources under references**.\n",
    "\n",
    "If you experience problems that you cannot solve using the course material or the Python documentation, or have any questions regarding to the programming assignments, please do not hesitate to contact the course assistant by e-mail at the address dip@unioulu.oulu.fi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Histogram operations\n",
    "\n",
    "In the following, you will have to analyze two images, `coffee.jpg` and `pout.tif`, and their histograms, and to compare the results of two histogram operations, namely histogram equalization and stretching. Now, perform the following operations in the reserved code cells and answer to the questions written in **bold** into the reserved spaces in **Finnish or English**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1. Display the images `coffee.jpg` and `pout.tif` and their histograms in the same figure.**\n",
    "\n",
    "Hint: You can plot the histogram of an image with matplotlib's __[`hist()`](https://matplotlib.org/devdocs/api/_as_gen/matplotlib.pyplot.hist.html)__ function but please note that you have to ravel the pixels of the 2D image into 1D array first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the test images\n",
    "coffee = (io.imread('coffee.jpg', as_gray=True) )  \n",
    "coffee = img_as_ubyte(coffee)\n",
    "pout = io.imread('pout.tif')\n",
    "\n",
    "# display the images and their histograms in the same figure\n",
    "fig, ax = plt.subplots(figsize=(16,16), nrows=2, ncols=2)\n",
    "ax[0,0].imshow(coffee)\n",
    "ax[0,0].axis('off')\n",
    "ax[0,1].hist(coffee.ravel())\n",
    "\n",
    "ax[1,0].imshow(pout)\n",
    "ax[1,0].axis('off')\n",
    "ax[1,1].hist(pout.ravel())\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram equalization\n",
    "\n",
    "**1.2. Perform histogram equalization with the function __[`exposure.equalize_hist()`](http://scikit-image.org/docs/dev/api/skimage.exposure.html#skimage.exposure.equalize_hist)__ and display the resulting images and their histograms in the same figure.**\n",
    "\n",
    "Hint: Please note that `exposure.equalize_hist()` function returns `float64` image. You need to __[convert the image back to `uint8`](http://scikit-image.org/docs/dev/user_guide/data_types.html)__ after histogram equalization so that the intensity value range of the resulting and original histograms are comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "# perform histogram equalization and convert data type from 'float64' back to 'uint8' after histogram equalization\n",
    "coffee_histeq = img_as_ubyte(exposure.equalize_hist(coffee))\n",
    "pout_histeq = img_as_ubyte(exposure.equalize_hist(pout))\n",
    "\n",
    "# display resulting images and their histograms in the same figure\n",
    "fig, ax = plt.subplots(figsize=(16,16), nrows=2, ncols=2)\n",
    "ax[0,0].imshow(coffee_histeq)\n",
    "ax[0,0].axis('off')\n",
    "ax[0,1].hist(coffee_histeq.ravel())\n",
    "\n",
    "ax[1,0].imshow(pout_histeq)\n",
    "ax[1,0].axis('off')\n",
    "ax[1,1].hist(pout_histeq.ravel())\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Again, compare the two images. Did histogram equalization help in increasing image contrast? Why or why not?**\n",
    "\n",
    "`In some sense the coffee image might be off worse now since all of the intensity spectrum was already represented, and now the whole image is brightened up, making the overall brightness of the image higher and making the details between dark and bright spots harder to see. The contrast in the image of the child is just slightly better since all of the spectrum is represented now, but the overall brightness is really high again and doesn't bring the best contrast.\n",
    "\n",
    "It seems as if the problem here is that histogram equalization (by its nature) doesn't retain the shape or structure of the histogram, and as such the images are quite plain, however brighter than before.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast stretching\n",
    "\n",
    "Another way of improving the contrast in an image is to simply stretch the original pixel values over an extended dynamic range using a linear scaling function. For instance, in case of an `uint8` image, the desired value range of a contrast-stretched image could be the full range from 0 to 255. \n",
    "\n",
    "Intuitively, one could perform contrast-stretching by selecting the minimum and maximum values of the original image and map these values to 0 and 255, respectively, and linearly scale all other pixel values in between accordingly. However, even a single outlier pixel value (high or low) can affect the input scaling range too much when outcome of the histogram stretching is not particularly good.\n",
    "\n",
    "A more robust approach is to map the intensity values so that e.g. 1st and 99th percentiles of the histogram are saturated at the minimum and maximum values of the desired intensity range. In other words, 1% of the pixels of both low and high intensities will be mapped to 0 and 255 in the contrast-stretched image while rest are scaled linearly in between."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3. Now, perform contrast stretching on the original images with the help of functions __[`np.percentile()`](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html)__ and __[`exposure.rescale_intensity()`](http://scikit-image.org/docs/dev/api/skimage.exposure.html#skimage.exposure.rescale_intensity)__ so that the full range from 0 and 255 is utilized based on the 1st and 99th percentiles of their histograms. Then, display the resulting images and their histograms in the same figure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the 1st and 99th percentiles of each image\n",
    "coffee_first = np.percentile(coffee, 1)\n",
    "coffee_last = np.percentile(coffee, 99)\n",
    "pout_first = np.percentile(pout, 1)\n",
    "pout_last = np.percentile(pout, 99)\n",
    "\n",
    "# rescale the intensities of both images to full 'uint8' range [0, 255] based on their 1st and 99th percentiles\n",
    "coffee_rescale = exposure.rescale_intensity(coffee, in_range = (coffee_first, coffee_last), out_range = (0, 255))\n",
    "pout_rescale = exposure.rescale_intensity(pout, in_range = (pout_first, pout_last), out_range = (0, 255))\n",
    "\n",
    "# display resulting images and their histograms\n",
    "fig, ax = plt.subplots(figsize=(16,16), nrows=2, ncols=2)\n",
    "ax[0,0].imshow(coffee_rescale)\n",
    "ax[0,0].axis('off')\n",
    "ax[0,1].hist(coffee_rescale.ravel())\n",
    "\n",
    "ax[1,0].imshow(pout_rescale)\n",
    "ax[1,0].axis('off')\n",
    "ax[1,1].hist(pout_rescale.ravel())\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n",
    "\n",
    "**1.4. Finally, display the original `coffee.jpg` image, and its histogram-equalized and contrast-stretched versions and the corresponding histograms into one figure (in total six images in one figure). Do the same for `pout.tif` as well.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 subplots for 'coffee.jpg'\n",
    "fig, ax = plt.subplots(figsize=(16,16), nrows=3, ncols=2)\n",
    "ax[0,0].imshow(coffee)\n",
    "ax[0,0].axis('off')\n",
    "ax[0,1].hist(coffee.ravel())\n",
    "\n",
    "ax[1,0].imshow(coffee_histeq)\n",
    "ax[1,0].axis('off')\n",
    "ax[1,1].hist(coffee_histeq.ravel())\n",
    "\n",
    "ax[2,0].imshow(coffee_rescale)\n",
    "ax[2,0].axis('off')\n",
    "ax[2,1].hist(coffee_rescale.ravel())\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "# 6 subplots for 'pout.tif'\n",
    "fig, ax = plt.subplots(figsize=(16,16), nrows=3, ncols=2)\n",
    "ax[0,0].imshow(pout)\n",
    "ax[0,0].axis('off')\n",
    "ax[0,1].hist(pout.ravel())\n",
    "\n",
    "ax[1,0].imshow(pout_histeq)\n",
    "ax[1,0].axis('off')\n",
    "ax[1,1].hist(pout_histeq.ravel())\n",
    "\n",
    "ax[2,0].imshow(pout_rescale)\n",
    "ax[2,0].axis('off')\n",
    "ax[2,1].hist(pout_rescale.ravel())\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Image sharpening\n",
    "\n",
    "First, read the part concerning sharpening spatial transforms in the lecture notes or in the course book.\n",
    "\n",
    "In this exercise, your task is to perform a sharpening transform to the image `moonunsharp.tif` in spatial domain enhancing the details, like edges, in the original grayscale image. The use of built-in functions that perform image sharpening from scratch, like `scipy.misc.imfilter()`, is forbidden but functions like __[`scipy.signal.convolve2d()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html)__ can be used for the task. You can select some method presented in the lecture notes or the course book, e.g. use Laplacian operator and convolution, for sharpening the test image. \n",
    "\n",
    "Please note that it does not matter what method you use or how “good” the sharpening looks as long as the sharpening can be observed in the end result. An example result achieved with __[`ImageFilter`](https://pillow.readthedocs.io/en/stable/reference/ImageFilter.html)__ is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image sharpening example using 'ImageFilter' module from PILLOW with 'image.filter()' function\n",
    "from PIL import ImageFilter, Image\n",
    "\n",
    "moon = Image.open('moonunsharp.tif')\n",
    "moon_sharp_example = moon.filter(ImageFilter.SHARPEN)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(moon, vmin=0, vmax=255, cmap=plt.get_cmap('gray'))\n",
    "ax[0].set_title('original')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(moon_sharp_example, vmin=0, vmax=255, cmap=plt.get_cmap('gray'))\n",
    "ax[1].set_title('sharpened')\n",
    "ax[1].axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1. Now, implement your own image sharpening transform and apply it on the test image.**\n",
    "\n",
    "Hint: Like in the previous task, please note the __[image data type (`dtype`) and corresponding value range](http://scikit-image.org/docs/dev/user_guide/data_types.html)__ after filtering/sharpening as unexpected errors with arithmetic may occur (see pre-tutorials) !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform image sharpening using e.g. a Laplacian mask and convolution\n",
    "from scipy import signal\n",
    "\n",
    "# defining Laplacian mask\n",
    "mask_laplace = [[0, -1, 0], [-1, 4, -1], [0, -1, 0]]\n",
    "\n",
    "# sharpening the image with convolution\n",
    "laplace_conv = img_as_ubyte(signal.convolve2d(moon, mask_laplace, mode = 'same'))\n",
    "sharp_laplace = moon + (0.91 * laplace_conv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2. Display the original and sharpened moon images in the same figure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot original and sharpened moon images in the same figure\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(moon, vmin=0, vmax=255, cmap=plt.get_cmap('gray'))\n",
    "ax[0].set_title('original')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(sharp_laplace, vmin=0, vmax=255, cmap=plt.get_cmap('gray'))\n",
    "ax[1].set_title('sharpened')\n",
    "ax[1].axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aftermath\n",
    "Finally, fill your answers to the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "`Laplacian filter from course material.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Submission\n",
    "\n",
    "1. Before submitting your work, **check that your notebook (code) runs from scratch** and reproduces all the requested results by clicking on the menu `Kernel -> Restart & Run All`! Also, check that you have answered all the questions written in **bold**.\n",
    "2. Clear all outputs and variables, etc. by click on the menu `Kernel -> Restart & Clear Output`. This may (or will) reduce the file size of your deliverable a lot! \n",
    "3. Rename this Jupyter notebook to **`DIP_PA1_[student number(s)].ipynb`** (e.g. `DIP_PA1_1234567.ipynb` if solo work or `DIP_PA1_1234567-7654321.ipynb` if working in a pair)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

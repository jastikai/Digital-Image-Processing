{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division     # Python 2/3 compatibility\n",
    "from skimage import io                              # utilities to read and write images in various formats\n",
    "import numpy as np                                  # array manipulation package\n",
    "import matplotlib.pyplot as plt                      # plotting package\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (30, 15)           # set default figure size\n",
    "plt.rcParams['image.cmap'] = 'gray'                 # set default colormap to gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digital Image Processing - Programming Assignment \n",
    "\n",
    "The following programming assignment involves image segmentation using two different methods, one is by using basic morphological operators and the other is using the more advanced technique of watershed segmentation. The deadline for returning your work is **29 April 2022 at 23:59. \n",
    "Please, follow carefully the submission instructions given in the end of this notebook.** You are encouraged to seek information in other places than the course book and lecture material but remember **list all your sources under references**.\n",
    "\n",
    "If you experience problems that you cannot solve using the course material or the Python documentation, or have any questions regarding to the programming assignments, please do not hesitate to contact the course assistant by e-mail at the address dip@unioulu.oulu.fi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Image segmentation - global thresholding\n",
    "\n",
    "In the following, you will apply global thresholding on the `eight.tif` test image to segment coins from uniform background. Let's take a look at the image and its histogram below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test image\n",
    "eight = io.imread('eight.tif')\n",
    "\n",
    "# plot test image and its histogram\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].imshow(eight, vmin=0, vmax=255, cmap=plt.get_cmap('gray'))\n",
    "ax[0].set_title('eight.tif')\n",
    "ax[0].axis('off')\n",
    "ax[1].hist(eight.flatten(), range=(0, 255) ,bins=50, fc='black')\n",
    "ax[1].set_title('histogram of the image')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is an evident difference in the instensity distribution of pixels belonging to the coins and the background. Therefore, global thresholding is enough for decent segmentation outcome in this case.\n",
    "\n",
    "The course book introduces the following algorithm for finding a global threshold `T`:\n",
    "1. Select an initial estimate for `T`. In this exercise, the initial estimate is selected to be the mean gray value of the image to be segmented.\n",
    "2. Segment the image using threshold `T`. This will produce two groups of pixels: `G1` consists of all pixels with gray level values `>T` and `G2` consisting of pixels with values `<=T`.\n",
    "3. Compute the average gray level values `u1` and `u2` for the pixels in regions `G1` and `G2`.\n",
    "4. Compute a new threshold value `T=0.5*(u1+u2)`.\n",
    "5. Repeat steps 2 through 4 until the difference (NOT remainder) in `T` in successive iterations is smaller than a predefined parameter `T0`. `T0`=1 in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.1. Now, fill the following template for function `findgraytresh()` so that it performs the algorithm described above. Test your function with the image `eight.tif`. Using the settings given above, you should obtain a threshold of `165.47`. If you do not get this value, there is something wrong with your implementation of the algorithm.**\n",
    "\n",
    "Hint: Since we are computing a threshold value to an `uint8` image, use the original `[0,255]` value range also when operating on `float64` type images instead of rescaling the pixel values to `[0,1]`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findgraytresh(im):\n",
    "    \n",
    "    # define 'T0'\n",
    "    T0 = 1\n",
    "    \n",
    "    # step 1: initialize 'T' as the mean grayscale value in the given image 'im'\n",
    "    T = np.mean(im.flatten())\n",
    "    T_prev = np.inf\n",
    "    \n",
    "    # repeat steps 2-4 until the difference in 'T' in successive iterations is smaller than 'T0=1'\n",
    "    while np.abs(T - T_prev) >= T0:\n",
    "        \n",
    "        # step 2: segment image using the current estimate of threshold 'T'\n",
    "        G1 = im[im > T]\n",
    "        G2 = im[im <= T]\n",
    "        \n",
    "        # step 3: compute the mean values 'u1' and 'u2' for the segmented foreground and background pixels\n",
    "        u1 = np.mean(G1.flatten())\n",
    "        u2 = np.mean(G2.flatten())\n",
    "        \n",
    "        # step 4: update threshold value 'T'\n",
    "        T_prev = T\n",
    "        T = 0.5 * (u1 + u2)\n",
    "\n",
    "    # return final estimate of 'T'\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the threshold value 'T' for test image using your implementation of 'findgraytresh()' function\n",
    "T = findgraytresh(eight)\n",
    "\n",
    "# display the threshold value 'T'\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.2. Perform global thresholding to the `eight.tif` image using the threshold value `T` obtained with your implementation of the `findgraythresh()` function and display the segmentation outcome (a binary image).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment the image\n",
    "eight_seg = np.zeros(np.shape(eight))\n",
    "eight_seg[eight > T] = 1\n",
    "\n",
    "# display the segmentation result\n",
    "plt.imshow(eight_seg)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the resulting image contains some unwanted noise (white dots in the coin area). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.3. Use morphological operator(s) erosion and/or dilation and proper structuring element to remove the segmentation noise and display the resulting image.**\n",
    "\n",
    "Hint: You can use e.g. __[`skimage.morphology`](http://scikit-image.org/docs/dev/api/skimage.morphology.html)__ package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "from skimage.morphology import disk\n",
    "\n",
    "# remove noise in the segmentation result using morphological operators\n",
    "eight_morph = morphology.erosion(eight_seg, disk(6))\n",
    "eight_morph = morphology.dilation(eight_morph, disk(6))\n",
    "\n",
    "# display the final segmentation result\n",
    "plt.imshow(eight_morph)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.4. Now, use morphological boundary extraction (see course book or lecture material) to the binary image to find the pixels belonging to the coin boundaries and superimpose the extracted boundaries on the original `eight.tif` image. Display the boundary image and the original image with superimposed boundaries in the same figure.**\n",
    "\n",
    "Hint: Assuming that the variable `boundary` contains the result of morphological binary extraction (logical image), the boundaries can be overlaid, e.g. by:\n",
    "\n",
    "`>>> eight[boundary] = 0`\n",
    "\n",
    "or with __[`matplotlib.pyplot.contour()`](https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.contour.html)__ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coin boundaries using morphological boundary extraction\n",
    "boundary = eight_morph - (morphology.erosion(eight_morph, disk(1)))\n",
    "\n",
    "# superimpose coin boundaries on the original test image\n",
    "eight = io.imread('eight.tif')\n",
    "eight[boundary == 1] = 0\n",
    "\n",
    "# display the extracted boundaries and the boundaries overlaid on the original image\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].imshow(eight, vmin=0, vmax=255, cmap=plt.get_cmap('gray'))\n",
    "ax[0].set_title('Original image with overlaid boundaries')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(boundary)\n",
    "ax[1].set_title('Boundaries')\n",
    "ax[1].axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Watersheds\n",
    "\n",
    "If the acquisition conditions are not optimal or the image is cluttered, global thresholding does not produce acceptable segmentation result. Here we simulate challenging lighting conditions by multiplying the image with a “lighting component”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "# introduce lighting component to the coin image\n",
    "eight = io.imread('eight.tif')\n",
    "light = loadmat('light.mat')['light']\n",
    "eight2 = eight*light\n",
    "\n",
    "# display the test image with and without additional lighting component\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(eight, vmin=0, vmax=255, cmap=plt.get_cmap('gray'))\n",
    "ax[0].set_title('eight.tif')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(eight2, vmin=0, vmax=255, cmap=plt.get_cmap('gray'))\n",
    "ax[1].set_title('eight.tif with lighting component')\n",
    "ax[1].axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.1. The resulting image cannot be probably segmented with the simple global thresholding method that you implemented in the previous task (`7.1`). Try, what happens and display the segmentation outcome and the histogram of the `eight2` image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find global threshold for the 'eight2' image using 'findgraytresh()' function\n",
    "T_2 = findgraytresh(eight2)\n",
    "print(T_2)\n",
    "\n",
    "# segment the 'eight2' image using the obtained threshold value\n",
    "eight_seg_2 = np.zeros(np.shape(eight2))\n",
    "eight_seg_2[eight2 > T_2] = 1\n",
    "\n",
    "# display the segmentation result and the histogram of the test image 'eight2'\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(eight_seg_2)\n",
    "ax[0].axis('off')\n",
    "ax[1].hist(eight2.flatten(), range=(0, 255) ,bins=50, fc='black')\n",
    "ax[1].axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, one can apply more advanced image segmentation algorithms, like watershed segmentation that we will use in the following task. First, read the part concerning watersheds in the lecture material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.2. Now, compute the gradient magnitude of the `eight2` image using Sobel mask. Then, display the image `eight2` and the gradient magnitude image in the same figure.**\n",
    "\n",
    "Hint: Compute first the horizontal and vertical gradient images, and then compute the gradient magnitude. You can use __[`scipy.ndimage.sobel()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.sobel.html#scipy.ndimage.sobel)__ function for computing the horizontal and vertical gradient images (`axis` parameter defines the direction of the gradient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "# compute horizontal gradient using Sobel mask\n",
    "dx = ndimage.sobel(eight2, axis = 0)\n",
    "\n",
    "# compute vertical gradient using Sobel mask\n",
    "dy = ndimage.sobel(eight2, axis = 1)\n",
    "\n",
    "# compute gradient magnitude \n",
    "grad_m = np.hypot(dx, dy)\n",
    "\n",
    "# plot test image and its gradient magnitude image\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(eight2)\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(grad_m)\n",
    "ax[1].axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create a marker image that introduces few seed pixels that are certain to belong into foreground objects and background. First, we introduce internal markers, i.e. pixels belonging to each coin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create marker image, i.e. create a set of basins that are certain to belong into foreground objects\n",
    "markers = np.zeros_like(eight2)\n",
    "markers[50,125]  = 1\n",
    "markers[149,75]  = 1\n",
    "markers[74,249]  = 1\n",
    "markers[199,199] = 1\n",
    "\n",
    "markers_internal = np.copy(markers)\n",
    "\n",
    "# plot gradient image\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(eight2, vmin=0, vmax=255, cmap=plt.get_cmap('gray'))\n",
    "ax[0].set_title('eight2 image')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(markers, cmap=plt.get_cmap('gray'))\n",
    "ax[1].set_title('marker image with foreground basins')\n",
    "ax[1].axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the set of internal markers can also be obtained automatically using, e.g. texture, size or shape of the objects but here we placed the markers by hand for the sake of simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need external markers that are certain to belong to background. Here we choose to mark to background some pixels that lie exactly midway between internal markers. This is can be done by computing the distance transform between the internal markers and by finding dense set of local maxima from the resulting distance map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import peak_local_max\n",
    "\n",
    "# compute distance transform for each white pixel\n",
    "distance_map = ndimage.distance_transform_edt(np.logical_not(markers_internal))\n",
    "\n",
    "# find local peaks in the distance map\n",
    "local_maxi = peak_local_max(distance_map, indices=False, min_distance=1)\n",
    "\n",
    "# set external markers to the marker image \n",
    "markers[local_maxi] = 2\n",
    "\n",
    "# display distance transform image and marker image with internal and external markers\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(distance_map, cmap=plt.get_cmap('gray'))\n",
    "ax[0].set_title('distance transform of internal markers')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(markers, cmap=plt.get_cmap('hot'))\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('internal and external markers')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every pixel value in the distance transform image tells the distance of a pixel to the closest internal marker (in pixels). The white pixels correspond to external markers and the red pixels to internal markers in marker image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.3. Now, apply watershed segmentation with function __[`skimage.morphology.watershed()`](http://scikit-image.org/docs/dev/api/skimage.morphology.html#skimage.morphology.watershed)__ on the gradient magnitude image using the defined markers and display the segmentation result.**\n",
    "\n",
    "Hint: Please note the output type of the function, which is a labeled matrix of the same type and shape as markers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import watershed\n",
    "# apply watershed segmentation on the gradient magnitude image with the markers (image) defined above\n",
    "ws_seg = watershed(grad_m, markers)\n",
    "\n",
    "# display the segmentation result\n",
    "plt.imshow(ws_seg)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.4. Finally, apply morphological boundary extraction on the segmentation result and superimpose the boundaries on the original `eight2` image like in 7.4.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform morphological boundary extraction\n",
    "boundary_2 = ws_seg - (morphology.erosion(ws_seg, disk(1)))\n",
    "\n",
    "# superimpose the extracted contours on the original test image\n",
    "eight = io.imread('eight.tif')\n",
    "light = loadmat('light.mat')['light']\n",
    "eight2 = eight*light\n",
    "eight2[boundary_2 == 1] = 0\n",
    "\n",
    "# display the test image overlaid segmentation result\n",
    "plt.imshow(eight2, vmin=0, vmax=255, cmap=plt.get_cmap('gray'))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Aftermath\n",
    "Finally, fill your answers to the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "`LIST YOUR REFERENCES HERE!`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Submission\n",
    "\n",
    "1. Before submitting your work, **check that your notebook (code) runs from scratch** and reproduces all the requested results by clicking on the menu `Kernel -> Restart & Run All`! Also, check that you have answered all the questions written in **bold**.\n",
    "2. Clear all outputs and variables, etc. by click on the menu `Kernel -> Restart & Clear Output`. This may (or will) reduce the file size of your deliverable a lot! \n",
    "3. Rename this Jupyter notebook to **`DIP_PA5_[student number(s)].ipynb`** (e.g. `DIP_PA5_1234567.ipynb` if solo work or `DIP_PA5_1234567-7654321.ipynb` if pair work) and upload it as your submission to Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
